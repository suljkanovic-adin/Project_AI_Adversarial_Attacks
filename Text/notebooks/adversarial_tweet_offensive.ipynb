{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17123,"status":"ok","timestamp":1732964492752,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"sBekRGX4tCUM","outputId":"f0219cae-b0b5-49cf-d790-84383b5882ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3475,"status":"ok","timestamp":1732964503274,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"g6WwCoh9KzYs","outputId":"5c301a50-0a28-40a9-fdb3-cb1a5424c130"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_RBhhWytXOr"},"outputs":[],"source":["output_dir = \"/content/drive/MyDrive/Master/models/tweet_offensive\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79345,"status":"ok","timestamp":1732964600534,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"mYHBrtjItOr3","outputId":"03e1c97c-8681-496c-918d-bc8c4cbdd874"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting textattack[optional,tensorflow]\n","  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n","Collecting bert-score>=0.3.5 (from textattack[optional,tensorflow])\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (0.8.1)\n","Collecting flair (from textattack[optional,tensorflow])\n","  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (3.16.1)\n","Collecting language-tool-python (from textattack[optional,tensorflow])\n","  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n","Collecting lemminflect (from textattack[optional,tensorflow])\n","  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n","Collecting lru-dict (from textattack[optional,tensorflow])\n","  Downloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n","Collecting datasets>=2.4.0 (from textattack[optional,tensorflow])\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (3.9.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (1.26.4)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (2.2.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (1.13.1)\n","Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (2.5.1+cu121)\n","Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (4.46.2)\n","Collecting terminaltables (from textattack[optional,tensorflow])\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (4.66.6)\n","Collecting word2number (from textattack[optional,tensorflow])\n","  Downloading word2number-1.1.zip (9.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting num2words (from textattack[optional,tensorflow])\n","  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (10.5.0)\n","Collecting pinyin>=0.4.0 (from textattack[optional,tensorflow])\n","  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (0.42.1)\n","Collecting OpenHowNet (from textattack[optional,tensorflow])\n","  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n","Requirement already satisfied: tensorflow>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (2.17.1)\n","Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (0.16.1)\n","Collecting tensorflow-text>=2.9.0 (from textattack[optional,tensorflow])\n","  Downloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting tensorboardX (from textattack[optional,tensorflow])\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n","Collecting sentence-transformers==2.2.0 (from textattack[optional,tensorflow])\n","  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting stanza (from textattack[optional,tensorflow])\n","  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n","Collecting visdom (from textattack[optional,tensorflow])\n","  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (0.18.7)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from textattack[optional,tensorflow]) (4.3.3)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (0.20.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (1.5.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (0.2.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (0.26.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (2.32.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (24.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.4.0->textattack[optional,tensorflow])\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting xxhash (from datasets>=2.4.0->textattack[optional,tensorflow])\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.4.0->textattack[optional,tensorflow])\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.4.0->textattack[optional,tensorflow])\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (3.11.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2024.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.37.1)\n","Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n","  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Collecting tensorboard<2.19,>=2.18 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n","  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack[optional,tensorflow]) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack[optional,tensorflow]) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack[optional,tensorflow]) (0.20.3)\n","Collecting boto3>=1.20.27 (from flair->textattack[optional,tensorflow])\n","  Downloading boto3-1.35.71-py3-none-any.whl.metadata (6.7 kB)\n","Collecting conllu<5.0.0,>=4.0 (from flair->textattack[optional,tensorflow])\n","  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair->textattack[optional,tensorflow]) (1.2.15)\n","Collecting ftfy>=6.1.0 (from flair->textattack[optional,tensorflow])\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack[optional,tensorflow]) (5.2.0)\n","Collecting langdetect>=1.0.9 (from flair->textattack[optional,tensorflow])\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack[optional,tensorflow]) (5.3.0)\n","Collecting mpld3>=0.3 (from flair->textattack[optional,tensorflow])\n","  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n","Collecting pptree>=3.1 (from flair->textattack[optional,tensorflow])\n","  Downloading pptree-3.1.tar.gz (3.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytorch-revgrad>=0.2.0 (from flair->textattack[optional,tensorflow])\n","  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n","Collecting segtok>=1.5.11 (from flair->textattack[optional,tensorflow])\n","  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n","Collecting sqlitedict>=2.0.0 (from flair->textattack[optional,tensorflow])\n","  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack[optional,tensorflow]) (0.9.0)\n","Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack[optional,tensorflow])\n","  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n","Collecting wikipedia-api>=0.5.7 (from flair->textattack[optional,tensorflow])\n","  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting semver<4.0.0,>=3.0.0 (from flair->textattack[optional,tensorflow])\n","  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n","Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack[optional,tensorflow])\n","  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->textattack[optional,tensorflow]) (7.0.5)\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack[optional,tensorflow]) (24.1.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack[optional,tensorflow]) (0.45.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->textattack[optional,tensorflow]) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack[optional,tensorflow]) (1.4.2)\n","Collecting docopt>=0.6.2 (from num2words->textattack[optional,tensorflow])\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting anytree (from OpenHowNet->textattack[optional,tensorflow])\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Collecting emoji (from stanza->textattack[optional,tensorflow])\n","  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza->textattack[optional,tensorflow]) (2.1.0)\n","Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub->textattack[optional,tensorflow]) (2.17.0)\n","Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom->textattack[optional,tensorflow]) (6.3.3)\n","Requirement already satisfied: jsonpatch in /usr/local/lib/python3.10/dist-packages (from visdom->textattack[optional,tensorflow]) (1.33)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom->textattack[optional,tensorflow]) (1.8.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom->textattack[optional,tensorflow]) (11.0.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (4.3.6)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (2.18.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->textattack[optional,tensorflow]) (1.3.4)\n","Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n","  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting botocore<1.36.0,>=1.35.71 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n","  Downloading botocore-1.35.71-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n","  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (4.0.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack[optional,tensorflow]) (0.2.13)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack[optional,tensorflow]) (4.12.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->textattack[optional,tensorflow]) (4.0.11)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.0->textattack[optional,tensorflow]) (3.5.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.1.3)\n","INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n","Collecting tf-keras>=2.14.1 (from tensorflow-hub->textattack[optional,tensorflow])\n","  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (3.0.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch->visdom->textattack[optional,tensorflow]) (3.0.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->textattack[optional,tensorflow]) (5.0.1)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack[optional,tensorflow]) (1.1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack[optional,tensorflow]) (2.6)\n","Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack[optional,tensorflow]) (1.7.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.1.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flair-0.14.0-py3-none-any.whl (776 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n","Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n","Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.7/445.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n","Downloading boto3-1.35.71-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n","Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n","Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n","Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.35.71-py3-none-any.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Building wheels for collected packages: sentence-transformers, pinyin, visdom, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120734 sha256=0e030a540283653cdea5023af2f1a8cf84c995e86b837e9d231418ffb30a2213\n","  Stored in directory: /root/.cache/pip/wheels/54/0d/ea/b89527acdff464eb4476a68607f6ca4e8ad24b6f6d5e8cfacb\n","  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630477 sha256=c1bbe601283f379888ecf54c1753893d93fb9c04ebd6f65cd60024ac45d5dc79\n","  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n","  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=0478325d3f645bc0290cb415ba4700f689d9a8b2a5f552d5e50eb2961721026f\n","  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=91bba76f2250190ab7c80cd1beeb09566fd77b19fb159f18e23521ad26168b29\n","  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=39d2cad7187413fe1f917c92e823901860f40c72cb6dc1b1f6e210236b279144\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=86af848b2dd5fa5da7adbc58355fa2c5eb201c4dca2e8113e11381c1d1ac24be\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=ed712f3f3bffb5ca4a809bdc7871c561843b45eff82d0ed42bdeaae0b90726e8\n","  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=ea79e3aac0b48dd9ead182078e1a355b298b8dbf8988422a0532439d454d39db\n","  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n","  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=b66f33431269f40b3ba345ed37343a94b4769bbc0326cc561f247d44cf567c4b\n","  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n","  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=3c5ccfda779d52a76b80bafc787ed88143b9180046585a09e33b0ddf8073820f\n","  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n","Successfully built sentence-transformers pinyin visdom word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n","Installing collected packages: word2number, sqlitedict, sortedcontainers, pptree, pinyin, docopt, xxhash, terminaltables, tensorflow-estimator, tensorboardX, semver, segtok, num2words, lru-dict, lemminflect, langdetect, jsonlines, jmespath, intervaltree, ftfy, fsspec, emoji, dill, conllu, anytree, wikipedia-api, visdom, tensorboard, OpenHowNet, multiprocess, language-tool-python, botocore, bioc, stanza, s3transfer, pytorch-revgrad, mpld3, tensorflow, boto3, tf-keras, tensorflow-text, sentence-transformers, datasets, bert-score, transformer-smaller-training-vocab, flair, textattack\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.17.1\n","    Uninstalling tensorboard-2.17.1:\n","      Successfully uninstalled tensorboard-2.17.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n","      Successfully uninstalled tensorflow-2.17.1\n","  Attempting uninstall: tf-keras\n","    Found existing installation: tf_keras 2.17.0\n","    Uninstalling tf_keras-2.17.0:\n","      Successfully uninstalled tf_keras-2.17.0\n","  Attempting uninstall: sentence-transformers\n","    Found existing installation: sentence-transformers 3.2.1\n","    Uninstalling sentence-transformers-3.2.1:\n","      Successfully uninstalled sentence-transformers-3.2.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed OpenHowNet-2.0 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 boto3-1.35.71 botocore-1.35.71 conllu-4.5.3 datasets-3.1.0 dill-0.3.8 docopt-0.6.2 emoji-2.14.0 flair-0.14.0 fsspec-2024.9.0 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 language-tool-python-2.8.1 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 multiprocess-0.70.16 num2words-0.5.13 pinyin-0.4.0 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.10.4 segtok-1.5.11 semver-3.0.2 sentence-transformers-2.2.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 stanza-1.9.2 tensorboard-2.18.0 tensorboardX-2.6.2.2 tensorflow-2.18.0 tensorflow-estimator-2.15.0 tensorflow-text-2.18.0 terminaltables-3.1.10 textattack-0.3.10 tf-keras-2.18.0 transformer-smaller-training-vocab-0.4.0 visdom-0.2.4 wikipedia-api-0.7.1 word2number-1.1 xxhash-3.5.0\n"]}],"source":["!pip install textattack[tensorflow,optional]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2881,"status":"ok","timestamp":1732888141224,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"0eDuyaoRtSUh","outputId":"e88bb1c9-38e5-44bc-e796-bffc6e264593"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.68.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.12.1)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.30)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.3)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.0)\n","Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.30)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.13.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n"]}],"source":["!pip install tensorflow==2.12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208406,"status":"ok","timestamp":1732888532253,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"qJmdiYTrtU8E","outputId":"55f65169-b5e7-4efd-cca7-7f511aca57f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-11-29 13:52:08.287948: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-29 13:52:08.290392: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-11-29 13:52:08.341452: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-11-29 13:52:08.342006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-29 13:52:09.430575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n","config.json: 100% 483/483 [00:00<00:00, 3.18MB/s]\n","model.safetensors: 100% 268M/268M [00:01<00:00, 199MB/s]\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 307kB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 1.05MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 1.10MB/s]\n","README.md: 100% 23.9k/23.9k [00:00<00:00, 79.7MB/s]\n","train-00000-of-00001.parquet: 100% 1.02M/1.02M [00:00<00:00, 266MB/s]\n","test-00000-of-00001.parquet: 100% 93.7k/93.7k [00:00<00:00, 204MB/s]\n","validation-00000-of-00001.parquet: 100% 122k/122k [00:00<00:00, 190MB/s]\n","Generating train split: 100% 11916/11916 [00:00<00:00, 233357.42 examples/s]\n","Generating test split: 100% 860/860 [00:00<00:00, 422130.07 examples/s]\n","Generating validation split: 100% 1324/1324 [00:00<00:00, 485891.90 examples/s]\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mtweet_eval\u001b[0m, subset \u001b[94moffensive\u001b[0m, split \u001b[94mtrain\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mtweet_eval\u001b[0m, subset \u001b[94moffensive\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Writing logs to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-clean/train_log.txt.\n","\u001b[34;1mtextattack\u001b[0m: Wrote original training args to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-clean/training_args.json.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n","\u001b[34;1mtextattack\u001b[0m:   Num examples = 11916\n","\u001b[34;1mtextattack\u001b[0m:   Num epochs = 5\n","\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 5\n","\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 64\n","\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 64\n","\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n","\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 935\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 1\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 1/5\n","Loss 0.56952: 100% 187/187 [00:17<00:00, 10.79it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 67.72%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 77.64%\n","\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-clean/best_model/\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 2\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 2/5\n","Loss 0.49514: 100% 187/187 [00:16<00:00, 11.61it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 81.47%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 79.76%\n","\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-clean/best_model/\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 3\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 3/5\n","Loss 0.44926: 100% 187/187 [00:16<00:00, 11.64it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 84.74%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 79.53%\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 4\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 4/5\n","Loss 0.39238: 100% 187/187 [00:16<00:00, 11.69it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 91.99%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 78.63%\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 5\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 5/5\n","Loss 0.33479: 100% 187/187 [00:16<00:00, 11.64it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 96.62%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 78.02%\n","\u001b[34;1mtextattack\u001b[0m: Wrote README to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-clean/README.md.\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 textattack train --model-name-or-path distilbert-base-uncased \\\n","                  --dataset tweet_eval^offensive \\\n","                  --model-num-labels 2 \\\n","                  --model-max-length 64 \\\n","                  --per-device-train-batch-size 64 \\\n","                  --num-epochs 5 \\\n","                  --output-dir {output_dir}/distilbert-tweet_offensive-clean\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4142327,"status":"ok","timestamp":1732782423604,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"Pd74vOtcwK61","outputId":"667f0907-d1ac-4fa0-ca45-931b6c1a4dd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34;1mtextattack\u001b[0m: Updating TextAttack package dependencies.\n","\u001b[34;1mtextattack\u001b[0m: Downloading NLTK required packages.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 31.0MB/s]        \n","2024-11-28 07:18:10 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-11-28 07:18:10 INFO: Downloading default packages for language: en (English) ...\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip: 100% 526M/526M [00:02<00:00, 204MB/s]\n","2024-11-28 07:18:14 INFO: Downloaded file to /root/stanza_resources/en/default.zip\n","2024-11-28 07:18:18 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-11-28 07:18:24.801833: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-28 07:18:24.805201: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-11-28 07:18:24.856501: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-11-28 07:18:24.857063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-28 07:18:25.819263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n","config.json: 100% 483/483 [00:00<00:00, 4.05MB/s]\n","model.safetensors: 100% 268M/268M [00:01<00:00, 220MB/s]\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 372kB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 5.78MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 30.0MB/s]\n","README.md: 100% 23.9k/23.9k [00:00<00:00, 94.8MB/s]\n","train-00000-of-00001.parquet: 100% 1.02M/1.02M [00:00<00:00, 283MB/s]\n","test-00000-of-00001.parquet: 100% 93.7k/93.7k [00:00<00:00, 220MB/s]\n","validation-00000-of-00001.parquet: 100% 122k/122k [00:00<00:00, 287MB/s]\n","Generating train split: 100% 11916/11916 [00:00<00:00, 226411.02 examples/s]\n","Generating test split: 100% 860/860 [00:00<00:00, 413943.25 examples/s]\n","Generating validation split: 100% 1324/1324 [00:00<00:00, 483944.10 examples/s]\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mtweet_eval\u001b[0m, subset \u001b[94moffensive\u001b[0m, split \u001b[94mtrain\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mtweet_eval\u001b[0m, subset \u001b[94moffensive\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n","\u001b[34;1mtextattack\u001b[0m: Writing logs to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-deepwordbug/train_log.txt.\n","\u001b[34;1mtextattack\u001b[0m: Wrote original training args to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-deepwordbug/training_args.json.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n","\u001b[34;1mtextattack\u001b[0m:   Num examples = 11916\n","\u001b[34;1mtextattack\u001b[0m:   Num epochs = 5\n","\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 1\n","\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 64\n","\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 64\n","\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n","\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 1679\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 1\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 1/1\n","Loss 0.55654: 100% 187/187 [00:17<00:00, 10.62it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 72.35%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 78.85%\n","\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-deepwordbug/best_model/\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 2\n","\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n","[Succeeded / Failed / Skipped / Total] 479 / 654 / 273 / 1406:  12% 1406/11916 [02:11<16:22, 10.69it/s]Building prefix dict from the default dictionary ...\n","Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.773 seconds.\n","Loading model cost 0.773 seconds.\n","Prefix dict has been built successfully.\n","Prefix dict has been built successfully.\n","[Succeeded / Failed / Skipped / Total] 4133 / 5502 / 2281 / 11916: 100% 11916/11916 [20:31<00:00,  9.67it/s]\n","\n","\n","\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 11916\n","\u001b[34;1mtextattack\u001b[0m: Attack success rate: 42.90% [4133 / 9635]\n","Loss 0.50457: 100% 251/251 [00:21<00:00, 11.70it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 77.72%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 78.17%\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 3\n","\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n","[Succeeded / Failed / Skipped / Total] 9409 / 842 / 1665 / 11916: 100% 11916/11916 [15:00<00:00, 13.23it/s]\n","\n","\n","\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 11916\n","\u001b[34;1mtextattack\u001b[0m: Attack success rate: 91.79% [9409 / 10251]\n","Loss 0.43344: 100% 334/334 [00:28<00:00, 11.79it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 86.02%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 78.70%\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 4\n","\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n","[Succeeded / Failed / Skipped / Total] 10939 / 196 / 781 / 11916: 100% 11916/11916 [15:35<00:00, 12.73it/s]\n","\n","\n","\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 11916\n","\u001b[34;1mtextattack\u001b[0m: Attack success rate: 98.24% [10939 / 11135]\n","Loss 0.36559: 100% 358/358 [00:30<00:00, 11.82it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 91.39%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 75.53%\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 5\n","\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n","[Succeeded / Failed / Skipped / Total] 11358 / 163 / 395 / 11916: 100% 11916/11916 [14:37<00:00, 13.57it/s]\n","\n","\n","\u001b[34;1mtextattack\u001b[0m: Total number of attack results: 11916\n","\u001b[34;1mtextattack\u001b[0m: Attack success rate: 98.59% [11358 / 11521]\n","Loss 0.32272: 100% 364/364 [00:30<00:00, 11.82it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 93.01%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 76.44%\n","\u001b[34;1mtextattack\u001b[0m: Wrote README to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-deepwordbug/README.md.\n"]}],"source":["!textattack train --model-name-or-path distilbert-base-uncased \\\n","                  --dataset tweet_eval^offensive \\\n","                  --model-num-labels 2 \\\n","                  --model-max-length 64 \\\n","                  --per-device-train-batch-size 64 \\\n","                  --num-epochs 5 \\\n","                  --attack deepwordbug \\\n","                  --num-clean-epochs 1 \\\n","                  --attack-epoch-interval 1 \\\n","                  --output-dir {output_dir}/distilbert-tweet_offensive-deepwordbug"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3641,"status":"ok","timestamp":1732964671960,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"iLRjArOwAe2y","outputId":"21a17517-0b6a-4096-b141-71dbaaa80cc1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('averaged_perceptron_tagger_eng')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3544,"status":"ok","timestamp":1732890344628,"user":{"displayName":"samir elamrany","userId":"14590178410899129725"},"user_tz":-60},"id":"FCpktq_IT-Pm","outputId":"70899358-2201-48de-9dce-02b2aa515080"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: textattack in /usr/local/lib/python3.10/dist-packages (0.3.10)\n","Requirement already satisfied: bert-score>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.3.13)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.8.1)\n","Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (from textattack) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.16.1)\n","Requirement already satisfied: language-tool-python in /usr/local/lib/python3.10/dist-packages (from textattack) (2.8.1)\n","Requirement already satisfied: lemminflect in /usr/local/lib/python3.10/dist-packages (from textattack) (0.2.3)\n","Requirement already satisfied: lru-dict in /usr/local/lib/python3.10/dist-packages (from textattack) (1.3.0)\n","Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (3.1.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.9.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.23.5)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.2.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.13.1)\n","Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.5.1+cu121)\n","Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.46.2)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from textattack) (3.1.10)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.66.6)\n","Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from textattack) (1.1)\n","Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from textattack) (0.5.13)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (10.5.0)\n","Requirement already satisfied: pinyin>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.4.0)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n","Requirement already satisfied: OpenHowNet in /usr/local/lib/python3.10/dist-packages (from textattack) (2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.8.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (24.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.4.0->textattack) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.26.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2024.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.20.3)\n","Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.35.71)\n","Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.5.3)\n","Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.15)\n","Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (6.3.1)\n","Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (5.2.0)\n","Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.0.9)\n","Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (5.3.0)\n","Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.5.10)\n","Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.1)\n","Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.2.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.5.2)\n","Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.5.11)\n","Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (2.1.0)\n","Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.9.0)\n","Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.4.0)\n","Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.7.1)\n","Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.0.2)\n","Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (2.1)\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack) (24.1.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language-tool-python->textattack) (0.45.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.4.2)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->textattack) (0.6.2)\n","Requirement already satisfied: anytree in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (2.12.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (75.1.0)\n","Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (4.0.0)\n","Requirement already satisfied: intervaltree in /usr/local/lib/python3.10/dist-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (3.1.0)\n","Requirement already satisfied: botocore<1.36.0,>=1.35.71 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.35.71)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (0.10.4)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (4.25.5)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.2)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.6)\n","Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (5.9.5)\n"]}],"source":["!pip install textattack --upgrade\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-OTogrMxmWt","outputId":"c30e11ad-8688-40e9-c332-c728c3c9802b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34;1mtextattack\u001b[0m: Updating TextAttack package dependencies.\n","\u001b[34;1mtextattack\u001b[0m: Downloading NLTK required packages.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 37.9MB/s]        \n","2024-11-30 11:24:18 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-11-30 11:24:18 INFO: Downloading default packages for language: en (English) ...\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip: 100% 526M/526M [00:02<00:00, 240MB/s]\n","2024-11-30 11:24:21 INFO: Downloaded file to /root/stanza_resources/en/default.zip\n","2024-11-30 11:24:25 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-11-30 11:24:31.187727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1732965871.206908    7492 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1732965871.213341    7492 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-30 11:24:31.234323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n","config.json: 100% 483/483 [00:00<00:00, 3.52MB/s]\n","model.safetensors: 100% 268M/268M [00:01<00:00, 238MB/s]\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 413kB/s]\n","vocab.txt: 100% 232k/232k [00:00<00:00, 8.96MB/s]\n","tokenizer.json: 100% 466k/466k [00:00<00:00, 38.8MB/s]\n","README.md: 100% 8.07k/8.07k [00:00<00:00, 40.2MB/s]\n","train-00000-of-00001.parquet: 100% 18.6M/18.6M [00:00<00:00, 214MB/s]\n","test-00000-of-00001.parquet: 100% 1.23M/1.23M [00:00<00:00, 212MB/s]\n","Generating train split: 100% 120000/120000 [00:00<00:00, 644453.79 examples/s]\n","Generating test split: 100% 7600/7600 [00:00<00:00, 691213.88 examples/s]\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtrain\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtest\u001b[0m.\n","\u001b[34;1mtextattack\u001b[0m: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.\n","100% 481M/481M [00:11<00:00, 41.2MB/s]\n","\u001b[34;1mtextattack\u001b[0m: Unzipping file /root/.cache/textattack/tmp2gs53d0i.zip to /root/.cache/textattack/word_embeddings/paragramcf.\n","\u001b[34;1mtextattack\u001b[0m: Successfully saved word_embeddings/paragramcf to cache.\n","\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n","\u001b[34;1mtextattack\u001b[0m: Writing logs to /content/drive/MyDrive/Master/models/tweets_Cheikhna/distilbert-tweet_offensive-textfooler/train_log.txt.\n","\u001b[34;1mtextattack\u001b[0m: Wrote original training args to /content/drive/MyDrive/Master/models/tweets_Cheikhna/distilbert-tweet_offensive-textfooler/training_args.json.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n","\u001b[34;1mtextattack\u001b[0m:   Num examples = 120000\n","\u001b[34;1mtextattack\u001b[0m:   Num epochs = 5\n","\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 1\n","\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 64\n","\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 64\n","\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n","\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 16875\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 1\n","\u001b[34;1mtextattack\u001b[0m: Running clean epoch 1/1\n","Loss 0.28029: 100% 1875/1875 [09:45<00:00,  3.20it/s]\n","\u001b[34;1mtextattack\u001b[0m: Train accuracy: 90.55%\n","\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 93.78%\n","\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to /content/drive/MyDrive/Master/models/tweets_Cheikhna/distilbert-tweet_offensive-textfooler/best_model/\n","\u001b[34;1mtextattack\u001b[0m: ==========================================================\n","\u001b[34;1mtextattack\u001b[0m: Epoch 2\n","\u001b[34;1mtextattack\u001b[0m: Attacking model to generate new adversarial training set...\n","[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   0% 1/120000 [00:00<21:49:15,  1.53it/s]2024-11-30 11:35:52.365122: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0000 00:00:1732966552.365268    7492 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11673 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","[Succeeded / Failed / Skipped / Total] 61727 / 13630 / 3644 / 79001:  66% 79001/120000 [23:25:36<12:09:28,  1.07s/it]"]}],"source":["!CUDA_VISIBLE_DEVICES=0 textattack train --model-name-or-path distilbert-base-uncased \\\n","                  --dataset ag_news \\\n","                  --model-num-labels 4 \\\n","                  --model-max-length 64 \\\n","                  --per-device-train-batch-size 64 \\\n","                  --num-epochs 5 \\\n","                  --attack textfooler \\\n","                  --num-clean-epochs 1 \\\n","                  --attack-epoch-interval 1 \\\n","                  --output-dir {output_dir}/distilbert-tweet_offensive-textfooler"]},{"cell_type":"markdown","source":["**P.S.**\n","\n","The last training for \"distilbert-tweet_offensive-textfooler\" was an attempt to run the code using the gpu. The runtime session disconnected, hence, it is cut on the second epoch.\n","\n","However, the code was executed before this attempt fully, and the output can be found in the train log of the model. I will paste the original output below:\n","\n","Epoch 1\n","Running clean epoch 1/1\n","Train accuracy: 71.58%\n","Eval accuracy: 78.47%\n","Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/best_model/\n","==========================================================\n","Epoch 2\n","Attacking model to generate new adversarial training set...\n","Writing logs to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/train_log.txt.\n","Wrote original training args to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/training_args.json.\n","***** Running training *****\n","  Num examples = 11916\n","  Num epochs = 5\n","  Num clean epochs = 1\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient accumulation steps = 1\n","  Total optimization steps = 1679\n","==========================================================\n","Epoch 1\n","Running clean epoch 1/1\n","Train accuracy: 72.48%\n","Eval accuracy: 78.25%\n","Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/best_model/\n","==========================================================\n","Epoch 2\n","Attacking model to generate new adversarial training set...\n","Total number of attack results: 11916\n","Attack success rate: 69.49% [6651 / 9571]\n","Train accuracy: 78.78%\n","Eval accuracy: 79.15%\n","Best score found. Saved model to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/best_model/\n","==========================================================\n","Epoch 3\n","Attacking model to generate new adversarial training set...\n","Total number of attack results: 11916\n","Attack success rate: 58.66% [6099 / 10397]\n","Train accuracy: 80.17%\n","Eval accuracy: 78.17%\n","==========================================================\n","Epoch 4\n","Attacking model to generate new adversarial training set...\n","Total number of attack results: 11916\n","Attack success rate: 82.36% [9101 / 11050]\n","Train accuracy: 87.97%\n","Eval accuracy: 77.27%\n","==========================================================\n","Epoch 5\n","Attacking model to generate new adversarial training set...\n","Total number of attack results: 11916\n","Attack success rate: 85.52% [9943 / 11627]\n","Train accuracy: 91.45%\n","Eval accuracy: 75.91%\n","Wrote README to /content/drive/MyDrive/Master/models/tweet_offensive/distilbert-tweet_offensive-textfooler/README.md."],"metadata":{"id":"qbm0JA5ROqfN"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPEogQ7iYENaWgoblXZROze"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}